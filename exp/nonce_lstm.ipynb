{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3574610,"sourceType":"datasetVersion","datasetId":2147487},{"sourceId":5876099,"sourceType":"datasetVersion","datasetId":3377708},{"sourceId":7355788,"sourceType":"datasetVersion","datasetId":4272201}],"dockerImageVersionId":30627,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from typing import Optional\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom sklearn import datasets\n\n%matplotlib inline\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:35.817141Z","iopub.execute_input":"2024-01-08T14:45:35.817470Z","iopub.status.idle":"2024-01-08T14:45:39.967285Z","shell.execute_reply.started":"2024-01-08T14:45:35.817442Z","shell.execute_reply":"2024-01-08T14:45:39.966335Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# prepare data","metadata":{}},{"cell_type":"code","source":"# download dictionary\n\n#! curl https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt -o words_alpha.txt\n# ! curl https://www.mit.edu/~ecprice/wordlist.10000 -o words_alpha.txt\n\n# corpus_fn = 'words_alpha.txt'\ncorpus_fn = '/kaggle/input/eng-dictionary-data/words_alpha.txt'\n\nwith open(corpus_fn, 'r') as f:\n    wordlist = f.read().split()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:39.969255Z","iopub.execute_input":"2024-01-08T14:45:39.970243Z","iopub.status.idle":"2024-01-08T14:45:40.093515Z","shell.execute_reply.started":"2024-01-08T14:45:39.970205Z","shell.execute_reply":"2024-01-08T14:45:40.092579Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ncorpus_fn = '/kaggle/input/english-freq/english.txt'\n\ndf = pd.read_csv(corpus_fn, sep='\\t', header=None)\ndf[0] = df[0].apply(lambda x: round(x / 5000) if x / 1000 > 1 else 1)\nwordlist = []\n\nfor row in df.iterrows():\n    wordlist.extend([row[1][1]] * row[1][0])","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:40.095141Z","iopub.execute_input":"2024-01-08T14:45:40.095793Z","iopub.status.idle":"2024-01-08T14:45:45.581401Z","shell.execute_reply.started":"2024-01-08T14:45:40.095753Z","shell.execute_reply":"2024-01-08T14:45:45.580598Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"wordlist[::10000]","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.584153Z","iopub.execute_input":"2024-01-08T14:45:45.584976Z","iopub.status.idle":"2024-01-08T14:45:45.591601Z","shell.execute_reply.started":"2024-01-08T14:45:45.584939Z","shell.execute_reply":"2024-01-08T14:45:45.590702Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['you',\n 'are',\n 'fucking',\n 'willoughby',\n 'flagship',\n 'ruprecht',\n 'deneen',\n 'misdirect',\n 'atrophies',\n 'damita']"},"metadata":{}}]},{"cell_type":"code","source":"# wordlist = [word for word in wordlist if len(word) > 3]\nwordlist = [word for word in wordlist if isinstance(word, str) and len(word) > 2]","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.592680Z","iopub.execute_input":"2024-01-08T14:45:45.592935Z","iopub.status.idle":"2024-01-08T14:45:45.629024Z","shell.execute_reply.started":"2024-01-08T14:45:45.592912Z","shell.execute_reply":"2024-01-08T14:45:45.628155Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"len(wordlist)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.630054Z","iopub.execute_input":"2024-01-08T14:45:45.630308Z","iopub.status.idle":"2024-01-08T14:45:45.636149Z","shell.execute_reply.started":"2024-01-08T14:45:45.630285Z","shell.execute_reply":"2024-01-08T14:45:45.635139Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"92550"},"metadata":{}}]},{"cell_type":"code","source":"import random\n\nrandom.choice(wordlist)\n# wordlist","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.637168Z","iopub.execute_input":"2024-01-08T14:45:45.637431Z","iopub.status.idle":"2024-01-08T14:45:45.647353Z","shell.execute_reply.started":"2024-01-08T14:45:45.637408Z","shell.execute_reply":"2024-01-08T14:45:45.646362Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'sarris'"},"metadata":{}}]},{"cell_type":"code","source":"sum([isinstance(word, float) for word in wordlist])","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.648401Z","iopub.execute_input":"2024-01-08T14:45:45.648674Z","iopub.status.idle":"2024-01-08T14:45:45.670665Z","shell.execute_reply.started":"2024-01-08T14:45:45.648652Z","shell.execute_reply":"2024-01-08T14:45:45.669817Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# make character list\n\ndef build_char_list(wordlist):\n    charlist = set()\n    for word in wordlist:\n        charlist.update(word)\n    charlist.add('_') #begin char\n    charlist.add('^') # end character\n    return sorted(charlist)\n\nbuild_char_list(['abc', 'abd', 'aba'])","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.671729Z","iopub.execute_input":"2024-01-08T14:45:45.671988Z","iopub.status.idle":"2024-01-08T14:45:45.681772Z","shell.execute_reply.started":"2024-01-08T14:45:45.671966Z","shell.execute_reply":"2024-01-08T14:45:45.680983Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['^', '_', 'a', 'b', 'c', 'd']"},"metadata":{}}]},{"cell_type":"code","source":"charlist = build_char_list(wordlist)\ninput_dim = len(charlist)\ninput_length = max(32, len(max(wordlist, key=len)))\nprint('Number of unique characters: ', input_dim)\nprint('Max word length (32 if less): ', input_length)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.682726Z","iopub.execute_input":"2024-01-08T14:45:45.683056Z","iopub.status.idle":"2024-01-08T14:45:45.716538Z","shell.execute_reply.started":"2024-01-08T14:45:45.683032Z","shell.execute_reply":"2024-01-08T14:45:45.715683Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Number of unique characters:  28\nMax word length (32 if less):  34\n","output_type":"stream"}]},{"cell_type":"code","source":"charlist","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.720967Z","iopub.execute_input":"2024-01-08T14:45:45.721217Z","iopub.status.idle":"2024-01-08T14:45:45.727483Z","shell.execute_reply.started":"2024-01-08T14:45:45.721195Z","shell.execute_reply":"2024-01-08T14:45:45.726519Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['^',\n '_',\n 'a',\n 'b',\n 'c',\n 'd',\n 'e',\n 'f',\n 'g',\n 'h',\n 'i',\n 'j',\n 'k',\n 'l',\n 'm',\n 'n',\n 'o',\n 'p',\n 'q',\n 'r',\n 's',\n 't',\n 'u',\n 'v',\n 'w',\n 'x',\n 'y',\n 'z']"},"metadata":{}}]},{"cell_type":"code","source":"id2char = dict(zip(range(input_dim), charlist))\nchar2id = dict(zip(charlist, range(input_dim)))","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.728617Z","iopub.execute_input":"2024-01-08T14:45:45.728910Z","iopub.status.idle":"2024-01-08T14:45:45.736239Z","shell.execute_reply.started":"2024-01-08T14:45:45.728860Z","shell.execute_reply":"2024-01-08T14:45:45.735340Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#спиздил от шадовского курса\ndef to_matrix(lines, max_len=None, pad_begin=char2id['_'], pad_end=char2id['^'], dtype=np.int64):\n    \"\"\"Casts a list of lines into torch-digestable matrix\"\"\"\n    max_len = (max_len or max(map(len, lines))) + 2\n    lines_ix = np.full([len(lines), max_len], pad_end, dtype=dtype)\n    lines_ix[:, 0] = pad_begin\n    for i in range(len(lines)):\n        line_ix = list(map(char2id.get, lines[i][:max_len]))\n        lines_ix[i, 1:len(line_ix)+1] = line_ix\n    return lines_ix","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.737278Z","iopub.execute_input":"2024-01-08T14:45:45.737609Z","iopub.status.idle":"2024-01-08T14:45:45.747568Z","shell.execute_reply.started":"2024-01-08T14:45:45.737585Z","shell.execute_reply":"2024-01-08T14:45:45.746812Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"to_matrix(wordlist[:5])","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.748595Z","iopub.execute_input":"2024-01-08T14:45:45.748880Z","iopub.status.idle":"2024-01-08T14:45:45.761387Z","shell.execute_reply.started":"2024-01-08T14:45:45.748857Z","shell.execute_reply":"2024-01-08T14:45:45.760576Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([[ 1, 26, 16, 22,  0],\n       [ 1, 26, 16, 22,  0],\n       [ 1, 26, 16, 22,  0],\n       [ 1, 26, 16, 22,  0],\n       [ 1, 26, 16, 22,  0]])"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport torch.nn.functional as F\n\ndef compute_mask(input_ix, eos_ix=char2id['^']):\n    \"\"\" compute a boolean mask that equals \"1\" until first EOS (including that EOS) \"\"\"\n    return F.pad(torch.cumsum(input_ix == eos_ix, dim=-1)[..., :-1] < 1, pad=(1, 0, 0, 0), value=True)\n\ncompute_mask(torch.tensor(to_matrix(wordlist[:5]))).to(torch.int32)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:45:45.762474Z","iopub.execute_input":"2024-01-08T14:45:45.762782Z","iopub.status.idle":"2024-01-08T14:45:45.837550Z","shell.execute_reply.started":"2024-01-08T14:45:45.762759Z","shell.execute_reply":"2024-01-08T14:45:45.836649Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensor([[1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]], dtype=torch.int32)"},"metadata":{}}]},{"cell_type":"markdown","source":"[source](https://machinelearningmastery.com/text-generation-with-lstm-in-pytorch/)","metadata":{}},{"cell_type":"markdown","source":"## prepare model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\n \nclass CharModel(nn.Module):\n    def __init__(self, n_vocab=len(charlist)):\n        super().__init__()\n        self.embed = nn.Embedding(len(charlist), 64)\n        self.lstm = nn.GRU(input_size=64, hidden_size=256, num_layers=5, batch_first=True)\n        self.linear = nn.Linear(256, n_vocab)\n    def forward(self, x):\n        x = self.embed(x)\n        x, _ = self.lstm(x)\n        x = self.linear(x)\n        return x\n    def get_next_tokens(self, prefix, temperature=1.0, max_len=256):\n        prefix_ix = torch.as_tensor(to_matrix([prefix]), dtype=torch.int64).to('cuda')\n        with torch.no_grad():\n            probs = torch.softmax(self(prefix_ix)[0, -1], dim=-1).cpu().numpy()  # shape: [n_tokens]\n        return dict(zip(charlist, probs))","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:10:35.744058Z","iopub.execute_input":"2024-01-08T15:10:35.744407Z","iopub.status.idle":"2024-01-08T15:10:35.753509Z","shell.execute_reply.started":"2024-01-08T15:10:35.744381Z","shell.execute_reply":"2024-01-08T15:10:35.752514Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"model.eval()\nmodel.to('cuda')\nwith torch.no_grad():\n    probs = torch.softmax(model(torch.zeros((1, 1)).long().cuda())[0, -1], dim=-1).cpu().numpy()\nprobs.round(2)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:11:24.003167Z","iopub.execute_input":"2024-01-08T15:11:24.003886Z","iopub.status.idle":"2024-01-08T15:11:24.017239Z","shell.execute_reply.started":"2024-01-08T15:11:24.003849Z","shell.execute_reply":"2024-01-08T15:11:24.016298Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"array([0.03, 0.04, 0.04, 0.04, 0.04, 0.03, 0.04, 0.03, 0.04, 0.03, 0.04,\n       0.04, 0.04, 0.03, 0.04, 0.04, 0.04, 0.04, 0.04, 0.03, 0.04, 0.03,\n       0.04, 0.03, 0.03, 0.04, 0.04, 0.04], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"model = CharModel()","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:10:43.632003Z","iopub.execute_input":"2024-01-08T15:10:43.632370Z","iopub.status.idle":"2024-01-08T15:10:43.654338Z","shell.execute_reply.started":"2024-01-08T15:10:43.632320Z","shell.execute_reply":"2024-01-08T15:10:43.653574Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(wordlist)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:03:11.524931Z","iopub.execute_input":"2024-01-08T15:03:11.525311Z","iopub.status.idle":"2024-01-08T15:03:11.557989Z","shell.execute_reply.started":"2024-01-08T15:03:11.525270Z","shell.execute_reply":"2024-01-08T15:03:11.557082Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class Words(Dataset):\n    def __init__(self, wordlist):\n        self.wordlist = wordlist\n        \n    def __getitem__(self, idx):\n        return self.wordlist[idx]\n    \n    def __len__(self):\n        return len(self.wordlist)\n    \ndef custom_collate(words):\n    return torch.tensor(to_matrix(words))\n\ntrain_dataset = Words(train)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=256, collate_fn=custom_collate, shuffle=True, num_workers=2)\n\ntest_dataset = Words(test)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=256, collate_fn=custom_collate, shuffle=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:11:44.446604Z","iopub.execute_input":"2024-01-08T15:11:44.447261Z","iopub.status.idle":"2024-01-08T15:11:44.454195Z","shell.execute_reply.started":"2024-01-08T15:11:44.447222Z","shell.execute_reply":"2024-01-08T15:11:44.453224Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def loss(logits, answers, mask):\n    loss = nn.CrossEntropyLoss(reduction='none')(logits, answers) * mask\n    return loss[loss != 0.0].mean()  ","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:11:44.610693Z","iopub.execute_input":"2024-01-08T15:11:44.611495Z","iopub.status.idle":"2024-01-08T15:11:44.615877Z","shell.execute_reply.started":"2024-01-08T15:11:44.611465Z","shell.execute_reply":"2024-01-08T15:11:44.614902Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm, trange\nfrom IPython.display import clear_output\n\ndevice = 'cuda'\nmodel = model.to(device)\nmodel.train()\noptim = torch.optim.Adam(model.parameters(), lr=0.0001)\n\nth, vh = [], []\nfor epoch in trange(30):\n    train_history = []\n    val_history = []\n    for i, x in enumerate(train_loader):\n        x = x.to(device)\n        logits = model(x[:, :-1]).permute(0, 2, 1)\n        answers = x[:, 1:]\n        mask = compute_mask(x[:, 1:])\n        l_t = loss(logits, answers, mask)\n        train_history.append(l_t.detach().cpu().numpy())\n        optim.zero_grad()\n        l_t.backward()\n        optim.step()\n    th.append((epoch, np.mean(train_history)))\n    with torch.no_grad():\n        for i, x in enumerate(test_loader):\n            x = x.to(device)\n            logits = model(x[:, :-1]).permute(0, 2, 1)\n            answers = x[:, 1:]\n            mask = compute_mask(x)[:, 1:]\n            l_v = loss(logits, answers, mask)\n            val_history.append(l_v.detach().cpu().numpy())\n    vh.append((epoch, np.mean(val_history)))\n    print(f'train {epoch} {np.mean(train_history)}')\n    print(f'val {epoch} {np.mean(val_history)}')\n        \n    \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:11:56.044027Z","iopub.execute_input":"2024-01-08T15:11:56.044440Z","iopub.status.idle":"2024-01-08T15:14:20.593075Z","shell.execute_reply.started":"2024-01-08T15:11:56.044377Z","shell.execute_reply":"2024-01-08T15:14:20.591952Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stderr","text":"  3%|▎         | 1/30 [00:04<02:19,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 0 2.8548645973205566\nval 0 2.646972179412842\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 2/30 [00:09<02:14,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"train 1 2.5361733436584473\nval 1 2.4694573879241943\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 3/30 [00:14<02:09,  4.80s/it]","output_type":"stream"},{"name":"stdout","text":"train 2 2.439051866531372\nval 2 2.411015033721924\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 4/30 [00:19<02:05,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"train 3 2.387172222137451\nval 3 2.363158702850342\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 5/30 [00:24<02:00,  4.80s/it]","output_type":"stream"},{"name":"stdout","text":"train 4 2.3398258686065674\nval 4 2.3192696571350098\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 6/30 [00:28<01:55,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 5 2.2961318492889404\nval 5 2.279724359512329\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 7/30 [00:33<01:50,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 6 2.259925365447998\nval 6 2.2498133182525635\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 8/30 [00:38<01:46,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 7 2.2314658164978027\nval 7 2.2242565155029297\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 9/30 [00:43<01:41,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"train 8 2.207279682159424\nval 8 2.2055089473724365\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 10/30 [00:48<01:36,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 9 2.1864280700683594\nval 9 2.187302827835083\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 11/30 [00:53<01:31,  4.84s/it]","output_type":"stream"},{"name":"stdout","text":"train 10 2.167553663253784\nval 10 2.173428535461426\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 12/30 [00:57<01:27,  4.85s/it]","output_type":"stream"},{"name":"stdout","text":"train 11 2.1514484882354736\nval 11 2.1566061973571777\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 13/30 [01:02<01:22,  4.84s/it]","output_type":"stream"},{"name":"stdout","text":"train 12 2.135450839996338\nval 12 2.145413398742676\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 14/30 [01:07<01:17,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 13 2.12101411819458\nval 13 2.1328845024108887\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 15/30 [01:12<01:12,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 14 2.1075592041015625\nval 14 2.1193671226501465\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 16/30 [01:17<01:07,  4.80s/it]","output_type":"stream"},{"name":"stdout","text":"train 15 2.095742702484131\nval 15 2.1114795207977295\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 17/30 [01:21<01:02,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"train 16 2.0839576721191406\nval 16 2.101125478744507\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 18/30 [01:26<00:57,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"train 17 2.072908878326416\nval 17 2.092506170272827\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 19/30 [01:31<00:53,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 18 2.0621588230133057\nval 18 2.082587718963623\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 20/30 [01:36<00:48,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"train 19 2.0526044368743896\nval 19 2.076439380645752\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 21/30 [01:41<00:43,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 20 2.0432965755462646\nval 20 2.06821608543396\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 22/30 [01:45<00:38,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"train 21 2.034022092819214\nval 21 2.060514450073242\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 23/30 [01:50<00:33,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 22 2.0252137184143066\nval 22 2.0540268421173096\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 24/30 [01:55<00:28,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 23 2.0169296264648438\nval 23 2.047433376312256\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 25/30 [02:00<00:24,  4.83s/it]","output_type":"stream"},{"name":"stdout","text":"train 24 2.00905704498291\nval 24 2.042158842086792\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 26/30 [02:05<00:19,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 25 2.0012357234954834\nval 25 2.0361275672912598\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 27/30 [02:10<00:14,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 26 1.9937429428100586\nval 26 2.032172203063965\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 28/30 [02:14<00:09,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"train 27 1.9870915412902832\nval 27 2.0264222621917725\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 29/30 [02:19<00:04,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"train 28 1.9795420169830322\nval 28 2.0220792293548584\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [02:24<00:00,  4.82s/it]","output_type":"stream"},{"name":"stdout","text":"train 29 1.9728119373321533\nval 29 2.0162577629089355\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate(model, prefix='_', temperature=1.0, max_len=256):\n    with torch.no_grad():\n        while True:\n            token_probs = model.get_next_tokens(prefix)\n            tokens, probs = zip(*token_probs.items())\n            if temperature == 0:\n                next_token = tokens[np.argmax(probs)]\n            else:\n                probs = np.array([p ** (1. / temperature) for p in probs])\n                probs /= sum(probs)\n                next_token = np.random.choice(tokens, p=probs)\n\n            prefix += next_token\n            if next_token == '^' or len(prefix) > max_len: break\n    return prefix","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:19:16.575454Z","iopub.execute_input":"2024-01-08T15:19:16.575880Z","iopub.status.idle":"2024-01-08T15:19:16.583798Z","shell.execute_reply.started":"2024-01-08T15:19:16.575838Z","shell.execute_reply":"2024-01-08T15:19:16.582710Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"prefix = '_gr'\nfor _ in range(10):\n    print(generate(model, prefix, temperature=1.0))","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:19:58.608220Z","iopub.execute_input":"2024-01-08T15:19:58.608630Z","iopub.status.idle":"2024-01-08T15:19:58.645641Z","shell.execute_reply.started":"2024-01-08T15:19:58.608598Z","shell.execute_reply":"2024-01-08T15:19:58.644719Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"_gr^\n_gri^\n_gras^\n_gr^\n_grad^\n_grifia^\n_grg^\n_gre^\n_gr^\n_grik^\n","output_type":"stream"}]},{"cell_type":"code","source":"test_words = ['tkemali', 'train', 'rtain', 'aenocoeia', ]","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:20:20.487383Z","iopub.execute_input":"2024-01-08T15:20:20.487760Z","iopub.status.idle":"2024-01-08T15:20:20.492254Z","shell.execute_reply.started":"2024-01-08T15:20:20.487732Z","shell.execute_reply":"2024-01-08T15:20:20.491375Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm, trange\nfrom IPython.display import clear_output\n\ndevice = 'cuda'\nmodel = model.to(device)\nmodel.eval()\n\nvh = []\nfor word in test_words:\n    val_history = []\n    with torch.no_grad():\n#         x = x.to(device)\n        word_t = torch.tensor(to_matrix([word])).to(device)\n        logits = model(word_t[:, :-1]).permute(0, 2, 1)\n        answers = word_t[:, 1:]\n        mask = compute_mask(word_t)[:, 1:]\n        l_v = loss(logits, answers, mask)\n        perp = torch.exp(l_v)\n        perp = perp.detach().cpu().numpy()\n        val_history.append(perp)\n        print(f'perplexity on {word} {perp}')","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:21:32.893300Z","iopub.execute_input":"2024-01-08T15:21:32.893718Z","iopub.status.idle":"2024-01-08T15:21:32.911387Z","shell.execute_reply.started":"2024-01-08T15:21:32.893681Z","shell.execute_reply":"2024-01-08T15:21:32.910441Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"perplexity on tkemali 23.93702507019043\nperplexity on train 5.92509651184082\nperplexity on rtain 30.396867752075195\nperplexity on aenocoeia 47.84872817993164\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"?np.round","metadata":{"execution":{"iopub.status.busy":"2024-01-08T15:21:13.113959Z","iopub.execute_input":"2024-01-08T15:21:13.114629Z","iopub.status.idle":"2024-01-08T15:21:13.120971Z","shell.execute_reply.started":"2024-01-08T15:21:13.114595Z","shell.execute_reply":"2024-01-08T15:21:13.119951Z"},"trusted":true},"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m\nRound an array to the given number of decimals.\n\nSee Also\n--------\naround : equivalent function; see for details.\n\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py\n\u001b[0;31mType:\u001b[0m      function"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# exp_params = {\n#     'batch_size': [8, 32],\n#     'lr': [1e-5, 1e-3],\n#     'n_conv_filters': [32, 128],\n#     'n_fc_neurons': [32, 128],\n#     'ncritic': [-5, 1, 5]\n# }\n\n# n_runs = 1\n# for val in exp_params.values():\n#     n_runs *= len(val)\n# print(f'number of runs: {n_runs}')","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:47:23.527495Z","iopub.status.idle":"2024-01-08T14:47:23.528139Z","shell.execute_reply.started":"2024-01-08T14:47:23.527882Z","shell.execute_reply":"2024-01-08T14:47:23.527904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def run_experiment(exp_params):\n#     trainer = Trainer(\n#         models=gan_network,\n#         losses_list=[LeastSquaresDiscriminatorLoss(), LeastSquaresGeneratorLoss()],\n#         ncritic=exp_params['ncritic'], \n#         epochs=30, \n#         sample_size=1, \n#         checkpoints='./model/gan', \n#         retain_checkpoints=5, \n#         log_dir='./logs/', \n#         test_noise=None, \n#         nrow=8,\n#         device='cuda'\n#     )\n    \n#     run_name = '_'.join([f'{param}: {value}' for param, value in exp_params.items()])\n    \n#     PROJECT = 'nonce-cnn'\n#     wandb.init(project=PROJECT, name=run_name, resume=True)\n#     trainer.train(trainloader_chars)\n#     wandb.finish()\n#     print(run_name)\n#     print(*decode(trainer.generator(prior_chars.sample((10,))).detach().cpu().numpy()), sep='\\n')\n#     print('====================================\\n')","metadata":{"execution":{"iopub.status.busy":"2024-01-08T14:47:23.529204Z","iopub.status.idle":"2024-01-08T14:47:23.529663Z","shell.execute_reply.started":"2024-01-08T14:47:23.529431Z","shell.execute_reply":"2024-01-08T14:47:23.529452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}