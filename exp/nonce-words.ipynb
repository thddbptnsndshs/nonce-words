{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn import datasets\n",
    "from torch import nn, optim\n",
    "from typing_extensions import Literal\n",
    "\n",
    "%matplotlib inline\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm words_alpha*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 75880  100 75880    0     0   148k      0 --:--:-- --:--:-- --:--:--  148k\n"
     ]
    }
   ],
   "source": [
    "# download dictionary\n",
    "\n",
    "# ! curl https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt -o words_alpha.txt\n",
    "! curl https://www.mit.edu/~ecprice/wordlist.10000 -o words_alpha.txt\n",
    "\n",
    "corpus_fn = 'words_alpha.txt'\n",
    "# corpus_fn = 'https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt'\n",
    "\n",
    "with open(corpus_fn, 'r') as f:\n",
    "    wordlist = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandoned',\n",
       " 'abc',\n",
       " 'aberdeen',\n",
       " 'abilities',\n",
       " 'ability']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [word + '$' for word in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a$',\n",
       " 'aa$',\n",
       " 'aaa$',\n",
       " 'aaron$',\n",
       " 'ab$',\n",
       " 'abandoned$',\n",
       " 'abc$',\n",
       " 'aberdeen$',\n",
       " 'abilities$',\n",
       " 'ability$']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$', 'a', 'b', 'c', 'd']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make character list\n",
    "\n",
    "def build_char_list(wordlist):\n",
    "    charlist = set()\n",
    "    for word in wordlist:\n",
    "        charlist.update(word)\n",
    "    charlist.add('$') # end character\n",
    "    return sorted(charlist)\n",
    "\n",
    "build_char_list(['abc', 'abd', 'aba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(['a', 'b', 'cc'], key=len)\n",
    "all([type(w) == str for w in wordlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters:  27\n",
      "Max word length (32 if less):  32\n"
     ]
    }
   ],
   "source": [
    "charlist = build_char_list(wordlist)\n",
    "input_dim = len(charlist)\n",
    "input_length = max(32, len(max(wordlist, key=len)))\n",
    "print('Number of unique characters: ', input_dim)\n",
    "print('Max word length (32 if less): ', input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2char = dict(zip(range(input_dim), charlist))\n",
    "char2id = dict(zip(charlist, range(input_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def encode(wordlist, \n",
    "           charlist=charlist, \n",
    "           input_dim=input_dim, \n",
    "           input_length=input_length,\n",
    "           char2id=char2id,\n",
    "           unknown_policy='zero'):\n",
    "    inp = np.zeros((len(wordlist), input_length, input_dim))\n",
    "    for i, word in enumerate(wordlist):\n",
    "        if unknown_policy == 'skip':\n",
    "            ints = [char2id.get(x) for x in word if x in char2id.keys()]\n",
    "            inp[i, np.arange(len(ints)), ints] = 1\n",
    "        elif unknown_policy == 'zero':\n",
    "            ints = np.array([char2id.get(x) if x in char2id.keys() else -1 for x in word])\n",
    "            ints_bool = (ints != -1)\n",
    "            inp[i, np.arange(len(ints))[ints_bool], ints[ints_bool]] = 1\n",
    "    return inp\n",
    "\n",
    "def encode1d(wordlist, \n",
    "           charlist=charlist, \n",
    "           input_dim=input_dim, \n",
    "           input_length=input_length,\n",
    "           char2id=char2id,\n",
    "           unknown_policy='zero'):\n",
    "    inp = np.zeros((len(wordlist), input_length))\n",
    "    inp = inp - 1 # set non-character symbols to -1\n",
    "    for i, word in enumerate(wordlist):\n",
    "        if unknown_policy == 'skip':\n",
    "            ints = [char2id.get(x) for x in word if x in char2id.keys()]\n",
    "            inp[i, :len(ints)] = ints\n",
    "        elif unknown_policy == 'zero':\n",
    "            ints = np.array([char2id.get(x) if x in char2id.keys() else -1 for x in word])\n",
    "            inp[i, :len(ints)] = ints\n",
    "    return inp\n",
    "\n",
    "\n",
    "def decode(out, \n",
    "           charlist=charlist,\n",
    "           id2char=id2char):\n",
    "    texts = []\n",
    "    out = np.argmax(out, axis=2)\n",
    "    for output in out:\n",
    "        text = [id2char.get(x) for x in output if x in id2char.keys()]\n",
    "        if '$' in text:\n",
    "            text = text[:text.index('$')]\n",
    "        text = ''.join(text)\n",
    "        texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  2.,  2.,  2., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode1d(['aaabbb333'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vanilla GAN: MNIST\n",
    "\n",
    "Теперь давайте обучим ту же самую архитектуру на чуть-чуть более серьёзные данных. Попробуем генерировать цифры из датасета MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorChars(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_length=input_length, \n",
    "                 input_dim=input_dim,\n",
    "                 n_conv_filters=64,\n",
    "                 n_fc_neurons=128,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(input_dim, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   )\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   )\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        \n",
    "        dimension = 2\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(dimension, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(n_fc_neurons, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.fc3 = nn.Linear(n_fc_neurons, input_dim)\n",
    "\n",
    "    def forward(\n",
    "        self, z: torch.Tensor, y: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        x = self.conv1(z)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiscriminatorChars(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_length=32, \n",
    "                 input_dim=input_dim,\n",
    "                 n_conv_filters=64,\n",
    "                 n_fc_neurons=128,\n",
    "                 embedding_dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(input_dim, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   )\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   )\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        \n",
    "        dimension = 2\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(dimension, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(n_fc_neurons, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.fc3 = nn.Linear(n_fc_neurons, 1)\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, y: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        res = torch.sigmoid(x)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetChars:\n",
    "    def __init__(self, \n",
    "                 wordlist,\n",
    "                 test=False,\n",
    "                 emb=False,\n",
    "                ):\n",
    "        self.wordlist = wordlist\n",
    "        \n",
    "        if test:\n",
    "            self.charlist = charlist\n",
    "            self.id2char = id2char\n",
    "            self.char2id = char2id\n",
    "            self.input_dim = input_dim\n",
    "            self.input_length = input_length\n",
    "        else:\n",
    "            self.charlist = self.build_char_list()\n",
    "            self.id2char = dict(zip(range(input_dim), charlist))\n",
    "            self.char2id = dict(zip(charlist, range(input_dim)))\n",
    "            self.input_dim = len(charlist)\n",
    "            self.input_length = max(32, len(max(wordlist, key=len)))\n",
    "        if emb:\n",
    "            self.encoded_list = self.encode1d()\n",
    "        else:\n",
    "            self.encoded_list = self.encode()\n",
    "        \n",
    "    def build_char_list(self):\n",
    "        charlist = set()\n",
    "        for word in self.wordlist:\n",
    "            charlist.update(word)\n",
    "        charlist.add('$') # end character\n",
    "        return sorted(charlist)\n",
    "    \n",
    "    def encode(self, unknown_policy='zero'):\n",
    "        inp = np.zeros((len(self.wordlist), self.input_length, self.input_dim))\n",
    "        for i, word in enumerate(self.wordlist):\n",
    "            if unknown_policy == 'skip':\n",
    "                ints = [self.char2id.get(x) for x in word if x in self.char2id.keys()]\n",
    "                inp[i, np.arange(len(ints)), ints] = 1\n",
    "            elif unknown_policy == 'zero':\n",
    "                ints = np.array([self.char2id.get(x) if x in self.char2id.keys() else -1 for x in word])\n",
    "                ints_bool = (ints != -1)\n",
    "                inp[i, np.arange(len(ints))[ints_bool], ints[ints_bool]] = 1\n",
    "        return torch.Tensor(inp)\n",
    "\n",
    "    def encode1d(self, unknown_policy='zero'):\n",
    "        inp = np.zeros((len(self.wordlist), self.input_length))\n",
    "        inp = inp - 1 # set non-character symbols to -1\n",
    "        for i, word in enumerate(self.wordlist):\n",
    "            if unknown_policy == 'skip':\n",
    "                ints = [char2id.get(x) for x in word if x in self.char2id.keys()]\n",
    "                inp[i, :len(ints)] = ints\n",
    "            elif unknown_policy == 'zero':\n",
    "                ints = np.array([char2id.get(x) if x in self.char2id.keys() else -1 for x in word])\n",
    "                inp[i, :len(ints)] = ints\n",
    "        return inp\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_list[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shikunova/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.Resize(32), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "# )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_wordlist, test_wordlist = train_test_split(\n",
    "     wordlist, test_size=0.2, random_state=42)\n",
    "\n",
    "trainset = DatasetChars(train_wordlist, emb=True)\n",
    "testset = DatasetChars(test_wordlist, emb=True)\n",
    "trainloader_chars = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=16, shuffle=True, num_workers=16, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.8.0 requires torch==1.8.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torchgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.quantized' has no attribute 'Dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-75d763493800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGeneratorChars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     def __init__(self, \n\u001b[1;32m      5\u001b[0m                  \u001b[0mencoding_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchgan/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchgan\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"v0.1.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"torchgan\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchgan/logging/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchgan/logging/logger.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTENSORBOARD_LOGGING\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchgan/logging/visualize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptical_flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/quantization/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmobilenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minception\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshufflenetv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/quantization/mobilenet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmobilenetv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantizableMobileNetV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmv2_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmobilenetv3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantizableMobileNetV3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobilenet_v3_large\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmv3_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmv2_all\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmv3_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/quantization/mobilenetv2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantStub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeQuantStub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenetv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInvertedResidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMobileNetV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_urls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/ao/quantization/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mqconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquant_type\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantization_mappings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantize_jit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/ao/quantization/quantization_mappings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnnq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm3d\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnnq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm3d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnnq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnnq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnnq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn.quantized' has no attribute 'Dropout'"
     ]
    }
   ],
   "source": [
    "from torchgan.models import Generator, Discriminator\n",
    "\n",
    "class GeneratorChars(Generator):\n",
    "    def __init__(self, \n",
    "                 encoding_dims=None,\n",
    "                 input_length=input_length, \n",
    "                 input_dim=32,\n",
    "                 n_conv_filters=64,\n",
    "                 n_fc_neurons=128,\n",
    "                ):\n",
    "        super().__init__(encoding_dims=input_dim)\n",
    "        self.encoding_dims = input_dim\n",
    "        print(self.encoding_dims)\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(input_dim, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   )\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   )\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        \n",
    "        dimension = 2\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(dimension, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(n_fc_neurons, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.fc3 = nn.Linear(n_fc_neurons, input_dim)\n",
    "\n",
    "    def forward(\n",
    "        self, z: torch.Tensor, y: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        x = self.conv1(z)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiscriminatorChars(Discriminator):\n",
    "    def __init__(self, \n",
    "                 input_dims=None,\n",
    "                 input_length=32, \n",
    "                 input_dim=input_dim,\n",
    "                 n_conv_filters=64,\n",
    "                 n_fc_neurons=128,\n",
    "                 embedding_dim=128,\n",
    "                ):\n",
    "        super().__init__(input_dims=input_dim)\n",
    "        self.input_dims = input_dim\n",
    "        \n",
    "        self.emb = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(input_dim, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   )\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   )\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, padding=0), nn.ReLU(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        \n",
    "        dimension = 2\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(dimension, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(n_fc_neurons, n_fc_neurons), nn.Dropout(0.5))\n",
    "        self.fc3 = nn.Linear(n_fc_neurons, 1)\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, y: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        print(x.shape)\n",
    "        print(x)\n",
    "#         x = x.transpose(0, 1)\n",
    "        x = self.emb(x.long())\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        res = torch.sigmoid(x)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_chars = GeneratorChars(100)\n",
    "gen_chars.to(device)\n",
    "\n",
    "discr_chars = DiscriminatorChars()\n",
    "discr_chars.to(device)\n",
    "\n",
    "# prior_chars = torch.distributions.Normal(\n",
    "#     torch.zeros(input_dim, input_length).to(device), torch.ones(input_dim, input_length).to(device)\n",
    "# )\n",
    "\n",
    "gen_opt_chars = optim.Adam(gen_chars.parameters(), lr=3e-5)\n",
    "discr_opt_chars = optim.Adam(discr_chars.parameters(), lr=3e-5, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_network = {\n",
    "    \"generator\": {\n",
    "        \"name\": GeneratorChars,\n",
    "        \"args\": {\n",
    "            \"encoding_dims\": 100,\n",
    "        },\n",
    "        \"optimizer\": {\"name\": optim.Adam, \"args\": {\"lr\": 0.0001, \"betas\": (0.5, 0.999)}},\n",
    "    },\n",
    "    \"discriminator\": {\n",
    "        \"name\": DiscriminatorChars,\n",
    "        \"args\": {\n",
    "        },\n",
    "        \"optimizer\": {\"name\": optim.Adam, \"args\": {\"lr\": 0.0003, \"betas\": (0.5, 0.999)}},\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgan.trainer import Trainer\n",
    "from torchgan.losses import LeastSquaresDiscriminatorLoss, LeastSquaresGeneratorLoss\n",
    "\n",
    "trainer = Trainer(\n",
    "    models=gan_network,\n",
    "    losses_list=[LeastSquaresDiscriminatorLoss(), LeastSquaresGeneratorLoss()],\n",
    "    ncritic=1, \n",
    "    epochs=1, \n",
    "    sample_size=2, \n",
    "    checkpoints='./model/gan', \n",
    "    retain_checkpoints=5, \n",
    "#     recon='./images', \n",
    "    log_dir=None, \n",
    "    test_noise=None, \n",
    "    nrow=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(trainloader_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(\n",
    "    trainloader_chars,\n",
    "    gen_chars,\n",
    "    discr_chars,\n",
    "    gen_opt_chars,\n",
    "    discr_opt_chars,\n",
    "    gan_loss,\n",
    "    prior_chars,\n",
    "    num_epochs=8,\n",
    "    gen_steps=10,\n",
    "    discr_steps=1,\n",
    "    verbose_num_iters=100,\n",
    "#     data_type=\"mnist\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = prior_chars.sample((16,))\n",
    "\n",
    "sampled_chars = gen_chars(z)\n",
    "\n",
    "print(*decode(sampled_chars.detach().cpu().numpy()), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30553,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
